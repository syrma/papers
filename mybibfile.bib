@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{dahl2011context,
  title={Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition},
  author={Dahl, George E and Yu, Dong and Deng, Li and Acero, Alex},
  journal={IEEE Transactions on audio, speech, and language processing},
  volume={20},
  number={1},
  year={2011},
  publisher={IEEE}
}

@article{schulman2015highdimensional,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{xiao2018deep,
  title={A deep learning-based multi-model ensemble method for cancer prediction},
  author={Xiao, Yawen and Wu, Jun and Lin, Zongli and Zhao, Xiaodong},
  journal={Computer methods and programs in biomedicine},
  volume={153},
  year={2018},
  publisher={Elsevier}
}

@article{islam2017reproducibility,
  title={Reproducibility of benchmarked deep reinforcement learning tasks for continuous control},
  author={Islam, Riashat and Henderson, Peter and Gomrokchi, Maziar and Precup, Doina},
  journal={arXiv preprint arXiv:1708.04133},
  year={2017}
}

@misc{brockman2016openai,
    title={OpenAI Gym},
    author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
    year={2016},
    eprint={1606.01540},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@MISC{coumans2019pybullet,
author =   {Erwin Coumans and Yunfei Bai},
title =    {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
howpublished = {{http://pybullet.org}},
year = {2016--2019}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{pan2017virtual,
  title={Virtual to real reinforcement learning for autonomous driving},
  author={Pan, Xinlei and You, Yurong and Wang, Ziyan and Lu, Cewu},
  journal={arXiv preprint arXiv:1704.03952},
  year={2017}
}

@inproceedings{kempka2016vizdoom,
  title={Vizdoom: A doom-based ai research platform for visual reinforcement learning},
  author={Kempka, Micha{\l} and Wydmuch, Marek and Runc, Grzegorz and Toczek, Jakub and Ja{\'s}kowski, Wojciech},
  booktitle={2016 IEEE Conference on Computational Intelligence and Games (CIG)},
  pages={1--8},
  year={2016},
  organization={IEEE}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year={2012},
  organization={IEEE}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}


@inproceedings{kurutach2018model,
  title={Model-Ensemble Trust-Region Policy Optimization},
  author={Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  year={2018},
  publisher={American Association for the Advancement of Science}
}


@inproceedings{engstrom2020implementation,
  title={Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@inproceedings{andrychowicz2021matters,
  title={What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study},
  author={Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Rapha{\"e}l and Hussenot, L{\'e}onard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and others},
  booktitle={ICLR 2021-Ninth International Conference on Learning Representations},
  year={2021}
}

@article{dossa2021empirical,
  title={An Empirical Investigation of Early Stopping Optimizations in Proximal Policy Optimization},
  author={Dossa, Rousslan Fernand Julien and Huang, Shengyi and Onta{\~n}{\'o}n, Santiago and Matsubara, Takashi},
  journal={IEEE Access},
  volume={9},
  year={2021},
  publisher={IEEE}
}

@inproceedings{shengyi2022the37implementation,
  author = {Huang, Shengyi and Dossa, Rousslan Fernand Julien and Raffin, Antonin and Kanervisto, Anssi and Wang, Weixun},
  title = {The 37 Implementation Details of Proximal Policy Optimization},
  booktitle = {ICLR Blog Track},
  year = {2022},
  note  = {https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/}
}

@article{mirhoseini2021graph,
  title={A graph placement methodology for fast chip design},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe Wenjie and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Nazi, Azade and others},
  journal={Nature},
  volume={594},
  number={7862},
  pages={207--212},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}


